{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from viz.visualize import Visualizer\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # change to your device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dress_dresslen_train_test_splits.json\tdress_sleeve_train_test_splits.json\r\n",
      "dress_sleevelen_train_test_splits.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./data/dress_dresslen_train_test_splits.json\", \"r\") as infile:\n",
    "    data_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train_1', 'y_train_1', 'X_test_1', 'y_test_1', 'X_train_2', 'y_train_2', 'X_test_2', 'y_test_2', 'X_train_3', 'y_train_3', 'X_test_3', 'y_test_3', 'X_train_4', 'y_train_4', 'X_test_4', 'y_test_4', 'X_train_5', 'y_train_5', 'X_test_5', 'y_test_5', 'X_train_6', 'y_train_6', 'X_test_6', 'y_test_6', 'X_train_7', 'y_train_7', 'X_test_7', 'y_test_7', 'X_train_8', 'y_train_8', 'X_test_8', 'y_test_8', 'X_train_9', 'y_train_9', 'X_test_9', 'y_test_9', 'X_train_10', 'y_train_10', 'X_test_10', 'y_test_10'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/2/8/2893552_3773662.jpg',\n",
       " '/2/9/2982376_3889235.jpg',\n",
       " '/2/7/2783355_3578973.jpg',\n",
       " '/2/9/2974380_3918638.jpg',\n",
       " '/2/8/2886740_3675612.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['X_train_1'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.5\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train image paths: 167,742\n",
      "Number of test image paths: 18,638\n",
      "\n",
      "Sample paths:\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/8/2893552_3773662.jpg\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/6/2683298_3676896.jpg\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/4/2431229_3158108.jpg\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/5/2569101_3223742.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths_train = []\n",
    "image_paths_test = []\n",
    "\n",
    "root_data_dir = \"/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables\"\n",
    "\n",
    "for key, val in data_dict.items():\n",
    "    if 'X_train' in key:\n",
    "        image_paths_train.extend([root_data_dir + imgpath for imgpath in val])\n",
    "    elif 'X_test' in key:\n",
    "        image_paths_test.extend([root_data_dir + imgpath for imgpath in val])\n",
    "\n",
    "print(f\"Number of train image paths: {len(image_paths_train):,d}\")\n",
    "print(f\"Number of test image paths: {len(image_paths_test):,d}\")\n",
    "print()\n",
    "print(\"Sample paths:\")\n",
    "print(image_paths_train[0])\n",
    "print(image_paths_train[-1])\n",
    "print(image_paths_test[0])\n",
    "print(image_paths_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.dataloaders import get_mnist_dataloaders, get_fashion_mnist_dataloaders\n",
    "#train_loader, test_loader = get_mnist_dataloaders(batch_size=64)\n",
    "#train_loader, test_loader = get_fashion_mnist_dataloaders(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from utils.dataloaders_custom import get_imagelist_dataloader, ImageListDataset\n",
    "\n",
    "#composed = transforms.Compose([transforms.Resize((260,260)), transforms.ToTensor()])\n",
    "composed = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageListDataset(image_paths_train, transform=composed)\n",
    "test_dataset = ImageListDataset(image_paths_test, transform=composed)\n",
    "\n",
    "train_loader = get_imagelist_dataloader(batch_size=20, dataset_object=train_dataset)\n",
    "test_loader = get_imagelist_dataloader(batch_size=20, dataset_object=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "latent_spec = {'cont': 10,\n",
    "               'disc': [10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from jointvae.models_v1 import VAE\n",
    "from jointvae.models import VAE\n",
    "\n",
    "#model = VAE(latent_spec=latent_spec, img_size=(3, 260, 260), use_cuda=use_cuda)\n",
    "model = VAE(latent_spec=latent_spec, img_size=(3, 64, 64), use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (img_to_features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (features_to_hidden): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc_mean): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (fc_log_var): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (fc_alphas): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (features_to_img): Sequential(\n",
      "    (0): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, amsgrad=True) # added amsgrad # orig lr 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jointvae.training import Trainer\n",
    "\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "cont_capacity = [0.0, 5.0, 25000, 30.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 5.0, 25000, 30.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity,\n",
    "                 use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/167742\tLoss: 2836.089\n",
      "1000/167742\tLoss: 2435.052\n",
      "2000/167742\tLoss: 1539.812\n",
      "3000/167742\tLoss: 1419.947\n",
      "4000/167742\tLoss: 1387.930\n",
      "5000/167742\tLoss: 1355.027\n",
      "6000/167742\tLoss: 1350.809\n",
      "7000/167742\tLoss: 1339.796\n",
      "8000/167742\tLoss: 1367.289\n",
      "9000/167742\tLoss: 1345.060\n",
      "10000/167742\tLoss: 1336.565\n",
      "11000/167742\tLoss: 1332.512\n",
      "12000/167742\tLoss: 1315.887\n",
      "13000/167742\tLoss: 1327.997\n",
      "14000/167742\tLoss: 1331.076\n",
      "15000/167742\tLoss: 1310.714\n",
      "16000/167742\tLoss: 1320.737\n",
      "17000/167742\tLoss: 1313.769\n",
      "18000/167742\tLoss: 1289.622\n",
      "19000/167742\tLoss: 1284.920\n",
      "20000/167742\tLoss: 1285.379\n",
      "21000/167742\tLoss: 1294.884\n",
      "22000/167742\tLoss: 1280.471\n",
      "23000/167742\tLoss: 1280.193\n",
      "24000/167742\tLoss: 1271.653\n",
      "25000/167742\tLoss: 1266.280\n",
      "26000/167742\tLoss: 1287.138\n",
      "27000/167742\tLoss: 1248.366\n",
      "28000/167742\tLoss: 1252.842\n",
      "29000/167742\tLoss: 1242.234\n",
      "30000/167742\tLoss: 1246.277\n",
      "31000/167742\tLoss: 1262.468\n",
      "32000/167742\tLoss: 1247.468\n",
      "33000/167742\tLoss: 1248.933\n",
      "34000/167742\tLoss: 1236.049\n",
      "35000/167742\tLoss: 1232.997\n",
      "36000/167742\tLoss: 1245.819\n",
      "37000/167742\tLoss: 1232.293\n",
      "38000/167742\tLoss: 1228.679\n",
      "39000/167742\tLoss: 1231.788\n",
      "40000/167742\tLoss: 1244.219\n",
      "41000/167742\tLoss: 1217.687\n",
      "42000/167742\tLoss: 1222.580\n",
      "43000/167742\tLoss: 1226.725\n",
      "44000/167742\tLoss: 1214.848\n",
      "45000/167742\tLoss: 1213.406\n",
      "46000/167742\tLoss: 1226.520\n",
      "47000/167742\tLoss: 1235.378\n",
      "48000/167742\tLoss: 1209.506\n",
      "49000/167742\tLoss: 1207.568\n",
      "50000/167742\tLoss: 1211.036\n",
      "51000/167742\tLoss: 1226.967\n",
      "52000/167742\tLoss: 1222.863\n",
      "53000/167742\tLoss: 1227.128\n",
      "54000/167742\tLoss: 1218.588\n",
      "55000/167742\tLoss: 1205.387\n",
      "56000/167742\tLoss: 1198.435\n",
      "57000/167742\tLoss: 1205.289\n",
      "58000/167742\tLoss: 1201.046\n",
      "59000/167742\tLoss: 1213.467\n",
      "60000/167742\tLoss: 1207.854\n",
      "61000/167742\tLoss: 1191.706\n",
      "62000/167742\tLoss: 1201.518\n",
      "63000/167742\tLoss: 1196.623\n",
      "64000/167742\tLoss: 1208.246\n",
      "65000/167742\tLoss: 1195.374\n",
      "66000/167742\tLoss: 1204.435\n",
      "67000/167742\tLoss: 1214.567\n",
      "68000/167742\tLoss: 1204.288\n",
      "69000/167742\tLoss: 1204.269\n",
      "70000/167742\tLoss: 1200.756\n",
      "71000/167742\tLoss: 1203.086\n",
      "72000/167742\tLoss: 1200.448\n",
      "73000/167742\tLoss: 1203.573\n",
      "74000/167742\tLoss: 1205.509\n",
      "75000/167742\tLoss: 1201.911\n",
      "76000/167742\tLoss: 1203.477\n",
      "77000/167742\tLoss: 1205.390\n",
      "78000/167742\tLoss: 1196.671\n",
      "79000/167742\tLoss: 1186.390\n",
      "80000/167742\tLoss: 1186.132\n",
      "81000/167742\tLoss: 1182.857\n",
      "82000/167742\tLoss: 1199.102\n",
      "83000/167742\tLoss: 1206.424\n",
      "84000/167742\tLoss: 1198.434\n",
      "85000/167742\tLoss: 1204.443\n",
      "86000/167742\tLoss: 1184.933\n",
      "87000/167742\tLoss: 1186.735\n",
      "88000/167742\tLoss: 1189.062\n",
      "89000/167742\tLoss: 1188.281\n",
      "90000/167742\tLoss: 1203.685\n",
      "91000/167742\tLoss: 1206.933\n",
      "92000/167742\tLoss: 1175.126\n",
      "93000/167742\tLoss: 1178.399\n",
      "94000/167742\tLoss: 1194.367\n",
      "95000/167742\tLoss: 1207.602\n",
      "96000/167742\tLoss: 1179.050\n",
      "97000/167742\tLoss: 1173.941\n",
      "98000/167742\tLoss: 1181.464\n",
      "99000/167742\tLoss: 1180.750\n",
      "100000/167742\tLoss: 1183.194\n",
      "101000/167742\tLoss: 1202.016\n",
      "102000/167742\tLoss: 1189.540\n",
      "103000/167742\tLoss: 1194.944\n",
      "104000/167742\tLoss: 1180.000\n",
      "105000/167742\tLoss: 1174.977\n",
      "106000/167742\tLoss: 1196.965\n",
      "107000/167742\tLoss: 1185.967\n",
      "108000/167742\tLoss: 1193.515\n",
      "109000/167742\tLoss: 1180.424\n",
      "110000/167742\tLoss: 1190.254\n",
      "111000/167742\tLoss: 1185.018\n",
      "112000/167742\tLoss: 1161.838\n",
      "113000/167742\tLoss: 1176.360\n",
      "114000/167742\tLoss: 1176.130\n",
      "115000/167742\tLoss: 1177.144\n",
      "116000/167742\tLoss: 1176.956\n",
      "117000/167742\tLoss: 1187.881\n",
      "118000/167742\tLoss: 1178.991\n",
      "119000/167742\tLoss: 1186.264\n",
      "120000/167742\tLoss: 1170.814\n",
      "121000/167742\tLoss: 1173.104\n",
      "122000/167742\tLoss: 1188.841\n",
      "123000/167742\tLoss: 1190.678\n",
      "124000/167742\tLoss: 1178.249\n",
      "125000/167742\tLoss: 1165.456\n",
      "126000/167742\tLoss: 1199.803\n",
      "127000/167742\tLoss: 1166.534\n",
      "128000/167742\tLoss: 1182.807\n",
      "129000/167742\tLoss: 1164.484\n",
      "130000/167742\tLoss: 1168.170\n",
      "131000/167742\tLoss: 1172.101\n",
      "132000/167742\tLoss: 1179.914\n",
      "133000/167742\tLoss: 1193.574\n",
      "134000/167742\tLoss: 1185.304\n",
      "135000/167742\tLoss: 1180.048\n",
      "136000/167742\tLoss: 1180.453\n",
      "137000/167742\tLoss: 1173.694\n",
      "138000/167742\tLoss: 1177.107\n",
      "139000/167742\tLoss: 1165.437\n",
      "140000/167742\tLoss: 1176.249\n",
      "141000/167742\tLoss: 1162.109\n",
      "142000/167742\tLoss: 1152.572\n",
      "143000/167742\tLoss: 1180.330\n",
      "144000/167742\tLoss: 1181.306\n",
      "145000/167742\tLoss: 1165.540\n",
      "146000/167742\tLoss: 1167.974\n",
      "147000/167742\tLoss: 1170.674\n",
      "148000/167742\tLoss: 1171.126\n",
      "149000/167742\tLoss: 1170.676\n",
      "150000/167742\tLoss: 1166.931\n",
      "151000/167742\tLoss: 1169.795\n",
      "152000/167742\tLoss: 1181.526\n",
      "153000/167742\tLoss: 1166.599\n",
      "154000/167742\tLoss: 1164.535\n",
      "155000/167742\tLoss: 1178.323\n",
      "156000/167742\tLoss: 1164.152\n",
      "157000/167742\tLoss: 1159.621\n",
      "158000/167742\tLoss: 1179.159\n",
      "159000/167742\tLoss: 1175.383\n",
      "160000/167742\tLoss: 1176.081\n",
      "161000/167742\tLoss: 1164.529\n",
      "162000/167742\tLoss: 1179.782\n",
      "163000/167742\tLoss: 1174.716\n",
      "164000/167742\tLoss: 1180.104\n",
      "165000/167742\tLoss: 1154.999\n",
      "166000/167742\tLoss: 1160.197\n",
      "167000/167742\tLoss: 1180.281\n",
      "Epoch: 1 Average loss: 1221.85\n",
      "0/167742\tLoss: 1215.836\n",
      "1000/167742\tLoss: 1164.434\n",
      "2000/167742\tLoss: 1153.653\n",
      "3000/167742\tLoss: 1160.987\n",
      "4000/167742\tLoss: 1166.907\n",
      "5000/167742\tLoss: 1178.427\n",
      "6000/167742\tLoss: 1158.133\n",
      "7000/167742\tLoss: 1165.414\n",
      "8000/167742\tLoss: 1166.916\n",
      "9000/167742\tLoss: 1171.078\n",
      "10000/167742\tLoss: 1170.817\n",
      "11000/167742\tLoss: 1174.867\n",
      "12000/167742\tLoss: 1164.908\n",
      "13000/167742\tLoss: 1164.788\n",
      "14000/167742\tLoss: 1166.085\n",
      "15000/167742\tLoss: 1165.449\n",
      "16000/167742\tLoss: 1155.007\n",
      "17000/167742\tLoss: 1165.184\n",
      "18000/167742\tLoss: 1159.425\n",
      "19000/167742\tLoss: 1163.707\n",
      "20000/167742\tLoss: 1168.958\n",
      "21000/167742\tLoss: 1161.398\n",
      "22000/167742\tLoss: 1143.700\n",
      "23000/167742\tLoss: 1152.620\n",
      "24000/167742\tLoss: 1155.500\n",
      "25000/167742\tLoss: 1168.124\n",
      "26000/167742\tLoss: 1146.879\n",
      "27000/167742\tLoss: 1152.007\n",
      "28000/167742\tLoss: 1165.832\n",
      "29000/167742\tLoss: 1152.281\n",
      "30000/167742\tLoss: 1161.139\n",
      "31000/167742\tLoss: 1168.514\n",
      "32000/167742\tLoss: 1160.080\n",
      "33000/167742\tLoss: 1162.374\n",
      "34000/167742\tLoss: 1161.638\n",
      "35000/167742\tLoss: 1143.210\n",
      "36000/167742\tLoss: 1159.344\n",
      "37000/167742\tLoss: 1151.479\n",
      "38000/167742\tLoss: 1154.717\n",
      "39000/167742\tLoss: 1148.744\n",
      "40000/167742\tLoss: 1158.682\n",
      "41000/167742\tLoss: 1154.019\n",
      "42000/167742\tLoss: 1161.719\n",
      "43000/167742\tLoss: 1161.670\n",
      "44000/167742\tLoss: 1154.669\n",
      "45000/167742\tLoss: 1149.188\n",
      "46000/167742\tLoss: 1151.960\n",
      "47000/167742\tLoss: 1160.975\n",
      "48000/167742\tLoss: 1172.365\n",
      "49000/167742\tLoss: 1151.201\n",
      "50000/167742\tLoss: 1160.516\n",
      "51000/167742\tLoss: 1169.063\n",
      "52000/167742\tLoss: 1167.203\n",
      "53000/167742\tLoss: 1158.438\n",
      "54000/167742\tLoss: 1167.274\n",
      "55000/167742\tLoss: 1167.453\n",
      "56000/167742\tLoss: 1143.316\n",
      "57000/167742\tLoss: 1157.412\n",
      "58000/167742\tLoss: 1172.758\n",
      "59000/167742\tLoss: 1152.146\n",
      "60000/167742\tLoss: 1148.203\n",
      "61000/167742\tLoss: 1153.817\n",
      "62000/167742\tLoss: 1158.324\n",
      "63000/167742\tLoss: 1148.471\n",
      "64000/167742\tLoss: 1152.624\n",
      "65000/167742\tLoss: 1164.635\n",
      "66000/167742\tLoss: 1168.095\n",
      "67000/167742\tLoss: 1152.908\n",
      "68000/167742\tLoss: 1146.978\n",
      "69000/167742\tLoss: 1158.765\n",
      "70000/167742\tLoss: 1168.089\n",
      "71000/167742\tLoss: 1138.206\n",
      "72000/167742\tLoss: 1138.553\n",
      "73000/167742\tLoss: 1153.629\n",
      "74000/167742\tLoss: 1157.109\n",
      "75000/167742\tLoss: 1158.813\n",
      "76000/167742\tLoss: 1158.593\n",
      "77000/167742\tLoss: 1147.396\n",
      "78000/167742\tLoss: 1166.139\n",
      "79000/167742\tLoss: 1160.232\n",
      "80000/167742\tLoss: 1143.974\n",
      "81000/167742\tLoss: 1150.639\n",
      "82000/167742\tLoss: 1155.903\n",
      "83000/167742\tLoss: 1158.322\n",
      "84000/167742\tLoss: 1153.872\n",
      "85000/167742\tLoss: 1143.175\n",
      "86000/167742\tLoss: 1156.866\n",
      "87000/167742\tLoss: 1152.467\n",
      "88000/167742\tLoss: 1166.878\n",
      "89000/167742\tLoss: 1145.214\n",
      "90000/167742\tLoss: 1140.816\n",
      "91000/167742\tLoss: 1144.522\n",
      "92000/167742\tLoss: 1139.534\n",
      "93000/167742\tLoss: 1142.476\n",
      "94000/167742\tLoss: 1140.476\n",
      "95000/167742\tLoss: 1160.888\n",
      "96000/167742\tLoss: 1142.399\n",
      "97000/167742\tLoss: 1169.162\n",
      "98000/167742\tLoss: 1150.761\n",
      "99000/167742\tLoss: 1155.668\n",
      "100000/167742\tLoss: 1155.523\n",
      "101000/167742\tLoss: 1146.627\n",
      "102000/167742\tLoss: 1152.269\n",
      "103000/167742\tLoss: 1165.225\n",
      "104000/167742\tLoss: 1148.004\n",
      "105000/167742\tLoss: 1152.202\n",
      "106000/167742\tLoss: 1141.284\n",
      "107000/167742\tLoss: 1142.601\n",
      "108000/167742\tLoss: 1155.874\n",
      "109000/167742\tLoss: 1159.696\n",
      "110000/167742\tLoss: 1140.684\n",
      "111000/167742\tLoss: 1142.334\n",
      "112000/167742\tLoss: 1159.759\n",
      "113000/167742\tLoss: 1140.537\n",
      "114000/167742\tLoss: 1143.638\n",
      "115000/167742\tLoss: 1140.223\n",
      "116000/167742\tLoss: 1162.778\n",
      "117000/167742\tLoss: 1144.695\n",
      "118000/167742\tLoss: 1152.728\n",
      "119000/167742\tLoss: 1152.927\n",
      "120000/167742\tLoss: 1150.597\n",
      "121000/167742\tLoss: 1145.390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122000/167742\tLoss: 1154.110\n",
      "123000/167742\tLoss: 1159.725\n",
      "124000/167742\tLoss: 1156.037\n",
      "125000/167742\tLoss: 1145.645\n",
      "126000/167742\tLoss: 1151.117\n",
      "127000/167742\tLoss: 1158.272\n",
      "128000/167742\tLoss: 1131.610\n",
      "129000/167742\tLoss: 1144.172\n",
      "130000/167742\tLoss: 1144.308\n",
      "131000/167742\tLoss: 1144.943\n",
      "132000/167742\tLoss: 1150.766\n",
      "133000/167742\tLoss: 1156.026\n",
      "134000/167742\tLoss: 1159.668\n",
      "135000/167742\tLoss: 1140.138\n",
      "136000/167742\tLoss: 1152.661\n",
      "137000/167742\tLoss: 1150.571\n",
      "138000/167742\tLoss: 1133.499\n",
      "139000/167742\tLoss: 1160.535\n",
      "140000/167742\tLoss: 1142.486\n",
      "141000/167742\tLoss: 1145.103\n",
      "142000/167742\tLoss: 1146.185\n",
      "143000/167742\tLoss: 1152.941\n",
      "144000/167742\tLoss: 1160.805\n",
      "145000/167742\tLoss: 1132.364\n",
      "146000/167742\tLoss: 1140.348\n",
      "147000/167742\tLoss: 1144.176\n",
      "148000/167742\tLoss: 1148.573\n",
      "149000/167742\tLoss: 1140.276\n",
      "150000/167742\tLoss: 1153.005\n",
      "151000/167742\tLoss: 1144.512\n",
      "152000/167742\tLoss: 1146.774\n",
      "153000/167742\tLoss: 1133.058\n",
      "154000/167742\tLoss: 1142.521\n",
      "155000/167742\tLoss: 1146.512\n",
      "156000/167742\tLoss: 1144.035\n",
      "157000/167742\tLoss: 1135.414\n",
      "158000/167742\tLoss: 1131.003\n",
      "159000/167742\tLoss: 1130.617\n",
      "160000/167742\tLoss: 1130.496\n",
      "161000/167742\tLoss: 1147.126\n",
      "162000/167742\tLoss: 1141.863\n",
      "163000/167742\tLoss: 1148.289\n",
      "164000/167742\tLoss: 1142.252\n",
      "165000/167742\tLoss: 1136.933\n",
      "166000/167742\tLoss: 1146.571\n",
      "167000/167742\tLoss: 1135.528\n",
      "Epoch: 2 Average loss: 1153.12\n",
      "0/167742\tLoss: 1128.722\n",
      "1000/167742\tLoss: 1136.139\n",
      "2000/167742\tLoss: 1144.433\n",
      "3000/167742\tLoss: 1147.256\n",
      "4000/167742\tLoss: 1133.023\n",
      "5000/167742\tLoss: 1143.182\n",
      "6000/167742\tLoss: 1144.019\n",
      "7000/167742\tLoss: 1140.712\n",
      "8000/167742\tLoss: 1134.387\n",
      "9000/167742\tLoss: 1143.795\n",
      "10000/167742\tLoss: 1137.412\n",
      "11000/167742\tLoss: 1138.909\n",
      "12000/167742\tLoss: 1134.369\n",
      "13000/167742\tLoss: 1138.809\n",
      "14000/167742\tLoss: 1139.007\n",
      "15000/167742\tLoss: 1152.242\n",
      "16000/167742\tLoss: 1133.025\n",
      "17000/167742\tLoss: 1154.380\n",
      "18000/167742\tLoss: 1138.549\n",
      "19000/167742\tLoss: 1141.658\n",
      "20000/167742\tLoss: 1143.873\n",
      "21000/167742\tLoss: 1133.421\n",
      "22000/167742\tLoss: 1154.751\n",
      "23000/167742\tLoss: 1133.275\n",
      "24000/167742\tLoss: 1122.507\n",
      "25000/167742\tLoss: 1142.189\n",
      "26000/167742\tLoss: 1146.912\n",
      "27000/167742\tLoss: 1135.047\n",
      "28000/167742\tLoss: 1143.521\n",
      "29000/167742\tLoss: 1137.015\n",
      "30000/167742\tLoss: 1138.137\n",
      "31000/167742\tLoss: 1135.491\n",
      "32000/167742\tLoss: 1129.687\n",
      "33000/167742\tLoss: 1138.769\n",
      "34000/167742\tLoss: 1139.610\n",
      "35000/167742\tLoss: 1134.419\n",
      "36000/167742\tLoss: 1135.526\n",
      "37000/167742\tLoss: 1143.782\n",
      "38000/167742\tLoss: 1129.433\n",
      "39000/167742\tLoss: 1124.438\n",
      "40000/167742\tLoss: 1145.246\n",
      "41000/167742\tLoss: 1138.188\n",
      "42000/167742\tLoss: 1141.885\n",
      "43000/167742\tLoss: 1140.223\n",
      "44000/167742\tLoss: 1135.467\n",
      "45000/167742\tLoss: 1136.663\n",
      "46000/167742\tLoss: 1139.668\n",
      "47000/167742\tLoss: 1130.686\n",
      "48000/167742\tLoss: 1141.497\n",
      "49000/167742\tLoss: 1139.270\n",
      "50000/167742\tLoss: 1144.131\n",
      "51000/167742\tLoss: 1140.876\n",
      "52000/167742\tLoss: 1146.276\n",
      "53000/167742\tLoss: 1155.605\n",
      "54000/167742\tLoss: 1140.847\n",
      "55000/167742\tLoss: 1140.192\n",
      "56000/167742\tLoss: 1141.064\n",
      "57000/167742\tLoss: 1128.031\n",
      "58000/167742\tLoss: 1131.770\n",
      "59000/167742\tLoss: 1139.160\n",
      "60000/167742\tLoss: 1135.691\n",
      "61000/167742\tLoss: 1141.141\n",
      "62000/167742\tLoss: 1136.445\n",
      "63000/167742\tLoss: 1156.374\n",
      "64000/167742\tLoss: 1134.094\n",
      "65000/167742\tLoss: 1141.838\n",
      "66000/167742\tLoss: 1128.167\n",
      "67000/167742\tLoss: 1111.927\n",
      "68000/167742\tLoss: 1133.627\n",
      "69000/167742\tLoss: 1132.137\n",
      "70000/167742\tLoss: 1133.717\n",
      "71000/167742\tLoss: 1143.231\n",
      "72000/167742\tLoss: 1150.384\n",
      "73000/167742\tLoss: 1136.192\n",
      "74000/167742\tLoss: 1134.562\n",
      "75000/167742\tLoss: 1143.015\n",
      "76000/167742\tLoss: 1144.119\n",
      "77000/167742\tLoss: 1151.149\n",
      "78000/167742\tLoss: 1137.162\n",
      "79000/167742\tLoss: 1113.263\n",
      "80000/167742\tLoss: 1136.117\n",
      "81000/167742\tLoss: 1132.854\n",
      "82000/167742\tLoss: 1137.313\n",
      "83000/167742\tLoss: 1125.263\n",
      "84000/167742\tLoss: 1145.868\n",
      "85000/167742\tLoss: 1135.146\n",
      "86000/167742\tLoss: 1122.022\n",
      "87000/167742\tLoss: 1125.174\n",
      "88000/167742\tLoss: 1113.965\n",
      "89000/167742\tLoss: 1140.546\n",
      "90000/167742\tLoss: 1133.448\n",
      "91000/167742\tLoss: 1124.236\n",
      "92000/167742\tLoss: 1143.266\n",
      "93000/167742\tLoss: 1129.484\n",
      "94000/167742\tLoss: 1138.153\n",
      "95000/167742\tLoss: 1130.478\n",
      "96000/167742\tLoss: 1136.730\n",
      "97000/167742\tLoss: 1131.107\n",
      "98000/167742\tLoss: 1126.036\n",
      "99000/167742\tLoss: 1121.325\n",
      "100000/167742\tLoss: 1119.262\n"
     ]
    }
   ],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "\n",
    "trainer.train(train_loader, epochs=10, save_training_gif=('./training_rd1.gif', viz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a batch of data\n",
    "for batch, labels in test_loader:\n",
    "    break\n",
    "\n",
    "# Reconstruct data using Joint-VAE model\n",
    "recon = viz.reconstructions(batch)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(recon.numpy()[0, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "samples = viz.samples()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(samples.numpy()[0, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all traversals\n",
    "traversals = viz.all_latent_traversals(size=10)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=2, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=1, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=9, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jvae_fmnist_oct292018.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"statedict_\" + model_name) # save state dict\n",
    "torch.save(model, model_name) # save full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore Model from State Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd_model = VAE(latent_spec=latent_spec, img_size=(1, 32, 32))\n",
    "sd_model.load_state_dict(torch.load(\"statedict_\" + model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore Full Model\n",
    "* Note in this case the serialized data is bound to the specific classes and exact directory strucutre used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = torch.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
