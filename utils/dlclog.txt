commit 589b7562e6917bc74aa0e32ec89f939ccc5ba01c
Author: Jeff Coggshall <jeffrey.lee.coggshall@macys.com>
Date:   Wed Oct 31 15:56:32 2018 -0700

    fixed ImageListDataset to use PIL images

diff --git a/utils/dataloaders_custom.py b/utils/dataloaders_custom.py
index c21a2f2..df66b34 100644
--- a/utils/dataloaders_custom.py
+++ b/utils/dataloaders_custom.py
@@ -33,7 +33,7 @@ class Rescale(object):
 
         new_h, new_w = int(new_h), int(new_w)
 
-        img = transforms.Resize(image, (new_h, new_w),  interpolation=Image.BICUBIC)
+        img = transforms.Resize(image, (new_h, new_w),  interpolation=Image.BICUBIC,)
 
         return {'image': img}
 
@@ -81,7 +81,8 @@ class ImageListDataset(Dataset):
 
     def __getitem__(self, idx):
         sample_path = self.img_paths[idx]
-        sample = imread(sample_path)
+        #sample = imread(sample_path)
+        sample = Image.open(sample_path)
 
         if self.transform:
             sample = self.transform(sample)

commit 4e62f7becd7954c943c24cf698d1eb32ccb69983
Author: Jeff Coggshall <jeffrey.lee.coggshall@macys.com>
Date:   Wed Oct 31 14:54:08 2018 -0700

    interpolation

diff --git a/utils/dataloaders_custom.py b/utils/dataloaders_custom.py
index f8b583d..c21a2f2 100644
--- a/utils/dataloaders_custom.py
+++ b/utils/dataloaders_custom.py
@@ -5,6 +5,7 @@ import numpy as np
 from skimage.io import imread
 from torch.utils.data import Dataset, DataLoader
 from torchvision import datasets, transforms
+from PIL import Image
 
 class Rescale(object):
     """Rescale the image in a sample to a given size.

commit 113d19b33bf45e7eddb730434ca75da1c77b50c8
Author: Jeff Coggshall <jeffrey.lee.coggshall@macys.com>
Date:   Wed Oct 31 14:45:45 2018 -0700

    dataloader fix Rescale

diff --git a/utils/dataloaders_custom.py b/utils/dataloaders_custom.py
index b0c20e5..f8b583d 100644
--- a/utils/dataloaders_custom.py
+++ b/utils/dataloaders_custom.py
@@ -32,7 +32,7 @@ class Rescale(object):
 
         new_h, new_w = int(new_h), int(new_w)
 
-        img = transform.resize(image, (new_h, new_w))
+        img = transforms.Resize(image, (new_h, new_w),  interpolation=Image.BICUBIC)
 
         return {'image': img}
 

commit 4397bee52125ffaab82863bbef9632d9bbc676ba
Author: Jeff Coggshall <jeffrey.lee.coggshall@macys.com>
Date:   Wed Oct 31 14:22:54 2018 -0700

    Dataloader small fix

diff --git a/utils/dataloaders_custom.py b/utils/dataloaders_custom.py
index 60fcd61..b0c20e5 100644
--- a/utils/dataloaders_custom.py
+++ b/utils/dataloaders_custom.py
@@ -62,8 +62,8 @@ class CelebADataset(Dataset):
 
 def get_imagelist_dataloader(batch_size=30, dataset_object=None):
     """dataloader with (64, 64) images."""
-    if not list_of_image_paths:
-        raise Exception('Must provide a list of image paths')
+    if not dataset_object:
+        raise Exception('Must provide a Dataset object')
 
     imagelist_loader = DataLoader(dataset_object, batch_size=batch_size, shuffle=True)
 

commit 540e2d3bec6fee6efcc56dca2d8efe15a02d7f89
Author: Jeff Coggshall <jeffrey.lee.coggshall@macys.com>
Date:   Wed Oct 31 14:08:41 2018 -0700

    Changed dataset/dataloader structure

diff --git a/utils/dataloaders_custom.py b/utils/dataloaders_custom.py
index c8453cb..60fcd61 100644
--- a/utils/dataloaders_custom.py
+++ b/utils/dataloaders_custom.py
@@ -60,14 +60,13 @@ class CelebADataset(Dataset):
         # Since there are no labels, we just return 0 for the "label" here
         return sample, 0
 
-def get_imagelist_dataloader(batch_size=30, list_of_image_paths=None):
+def get_imagelist_dataloader(batch_size=30, dataset_object=None):
     """dataloader with (64, 64) images."""
     if not list_of_image_paths:
         raise Exception('Must provide a list of image paths')
-    imagelist_data = ImageListDataset(list_of_image_paths,
-                                transform=transforms.ToTensor())
-    imagelist_loader = DataLoader(imagelist_data, batch_size=batch_size,
-                               shuffle=True)
+
+    imagelist_loader = DataLoader(dataset_object, batch_size=batch_size, shuffle=True)
+
     return imagelist_loader
 
 class ImageListDataset(Dataset):

commit 38a270595e4c20130f7663730afdb7bbca70309a
Author: Jeff Coggshall <jeffrey.lee.coggshall@macys.com>
Date:   Wed Oct 31 12:36:21 2018 -0700

    Added rescaling to dataloader

diff --git a/utils/dataloaders_custom.py b/utils/dataloaders_custom.py
index e33d3d6..c8453cb 100644
--- a/utils/dataloaders_custom.py
+++ b/utils/dataloaders_custom.py
@@ -6,86 +6,35 @@ from skimage.io import imread
 from torch.utils.data import Dataset, DataLoader
 from torchvision import datasets, transforms
 
+class Rescale(object):
+    """Rescale the image in a sample to a given size.
 
-def get_mnist_dataloaders(batch_size=128, path_to_data='../data'):
-    """MNIST dataloader with (32, 32) images."""
-    all_transforms = transforms.Compose([
-        transforms.Resize(32),
-        transforms.ToTensor()
-    ])
-    train_data = datasets.MNIST(path_to_data, train=True, download=True,
-                                transform=all_transforms)
-    test_data = datasets.MNIST(path_to_data, train=False,
-                               transform=all_transforms)
-    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
-    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)
-    return train_loader, test_loader
-
-
-def get_chairs_dataloader(batch_size=128,
-                          path_to_data='../rendered_chairs_64'):
-    """Chairs dataloader. Chairs are center cropped and resized to (64, 64)."""
-    all_transforms = transforms.Compose([
-        transforms.Grayscale(),
-        transforms.ToTensor()
-    ])
-    chairs_data = datasets.ImageFolder(root=path_to_data,
-                                       transform=all_transforms)
-    chairs_loader = DataLoader(chairs_data, batch_size=batch_size,
-                               shuffle=True)
-    return chairs_loader
-
-
-def get_chairs_test_dataloader(batch_size=62,
-                               path_to_data='../rendered_chairs_64_test'):
-    """There are 62 pictures of each chair, so get batches of data containing
-    one chair per batch."""
-    all_transforms = transforms.Compose([
-        transforms.Grayscale(),
-        transforms.ToTensor()
-    ])
-    chairs_data = datasets.ImageFolder(root=path_to_data,
-                                       transform=all_transforms)
-    chairs_loader = DataLoader(chairs_data, batch_size=batch_size,
-                               shuffle=False)
-    return chairs_loader
-
-
-def get_celeba_dataloader(batch_size=128, path_to_data='../celeba_64'):
-    """CelebA dataloader with (64, 64) images."""
-    celeba_data = CelebADataset(path_to_data,
-                                transform=transforms.ToTensor())
-    celeba_loader = DataLoader(celeba_data, batch_size=batch_size,
-                               shuffle=True)
-    return celeba_loader
+    Args:
+        output_size (tuple or int): Desired output size. If tuple, output is
+            matched to output_size. If int, smaller of image edges is matched
+            to output_size keeping aspect ratio the same.
+    """
 
+    def __init__(self, output_size):
+        assert isinstance(output_size, (int, tuple))
+        self.output_size = output_size
 
-class DSpritesDataset(Dataset):
-    """D Sprites dataset."""
-    def __init__(self, path_to_data, subsample=1, transform=None):
-        """
-        Parameters
-        ----------
-        subsample : int
-            Only load every |subsample| number of images.
-        """
-        self.imgs = np.load(path_to_data)['imgs'][::subsample]
-        self.transform = transform
+    def __call__(self, image):
 
-    def __len__(self):
-        return len(self.imgs)
+        h, w = image.shape[:2]
+        if isinstance(self.output_size, int):
+            if h > w:
+                new_h, new_w = self.output_size * h / w, self.output_size
+            else:
+                new_h, new_w = self.output_size, self.output_size * w / h
+        else:
+            new_h, new_w = self.output_size
 
-    def __getitem__(self, idx):
-        # Each image in the dataset has binary values so multiply by 255 to get
-        # pixel values
-        sample = self.imgs[idx] * 255
-        # Add extra dimension to turn shape into (H, W) -> (H, W, C)
-        sample = sample.reshape(sample.shape + (1,))
+        new_h, new_w = int(new_h), int(new_w)
 
-        if self.transform:
-            sample = self.transform(sample)
-        # Since there are no labels, we just return 0 for the "label" here
-        return sample, 0
+        img = transform.resize(image, (new_h, new_w))
+
+        return {'image': img}
 
 class CelebADataset(Dataset):
     """CelebA dataset with 64 by 64 images."""

commit a1ef458cacc5426aa1683a212a8161c496d9a95b
Author: Jeff Coggshall <jeffrey.lee.coggshall@macys.com>
Date:   Tue Oct 30 16:45:21 2018 -0700

    Added custom dataloaders

diff --git a/utils/dataloaders_custom.py b/utils/dataloaders_custom.py
new file mode 100644
index 0000000..e33d3d6
--- /dev/null
+++ b/utils/dataloaders_custom.py
@@ -0,0 +1,140 @@
+
+import cv2
+import glob
+import numpy as np
+from skimage.io import imread
+from torch.utils.data import Dataset, DataLoader
+from torchvision import datasets, transforms
+
+
+def get_mnist_dataloaders(batch_size=128, path_to_data='../data'):
+    """MNIST dataloader with (32, 32) images."""
+    all_transforms = transforms.Compose([
+        transforms.Resize(32),
+        transforms.ToTensor()
+    ])
+    train_data = datasets.MNIST(path_to_data, train=True, download=True,
+                                transform=all_transforms)
+    test_data = datasets.MNIST(path_to_data, train=False,
+                               transform=all_transforms)
+    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
+    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)
+    return train_loader, test_loader
+
+
+def get_chairs_dataloader(batch_size=128,
+                          path_to_data='../rendered_chairs_64'):
+    """Chairs dataloader. Chairs are center cropped and resized to (64, 64)."""
+    all_transforms = transforms.Compose([
+        transforms.Grayscale(),
+        transforms.ToTensor()
+    ])
+    chairs_data = datasets.ImageFolder(root=path_to_data,
+                                       transform=all_transforms)
+    chairs_loader = DataLoader(chairs_data, batch_size=batch_size,
+                               shuffle=True)
+    return chairs_loader
+
+
+def get_chairs_test_dataloader(batch_size=62,
+                               path_to_data='../rendered_chairs_64_test'):
+    """There are 62 pictures of each chair, so get batches of data containing
+    one chair per batch."""
+    all_transforms = transforms.Compose([
+        transforms.Grayscale(),
+        transforms.ToTensor()
+    ])
+    chairs_data = datasets.ImageFolder(root=path_to_data,
+                                       transform=all_transforms)
+    chairs_loader = DataLoader(chairs_data, batch_size=batch_size,
+                               shuffle=False)
+    return chairs_loader
+
+
+def get_celeba_dataloader(batch_size=128, path_to_data='../celeba_64'):
+    """CelebA dataloader with (64, 64) images."""
+    celeba_data = CelebADataset(path_to_data,
+                                transform=transforms.ToTensor())
+    celeba_loader = DataLoader(celeba_data, batch_size=batch_size,
+                               shuffle=True)
+    return celeba_loader
+
+
+class DSpritesDataset(Dataset):
+    """D Sprites dataset."""
+    def __init__(self, path_to_data, subsample=1, transform=None):
+        """
+        Parameters
+        ----------
+        subsample : int
+            Only load every |subsample| number of images.
+        """
+        self.imgs = np.load(path_to_data)['imgs'][::subsample]
+        self.transform = transform
+
+    def __len__(self):
+        return len(self.imgs)
+
+    def __getitem__(self, idx):
+        # Each image in the dataset has binary values so multiply by 255 to get
+        # pixel values
+        sample = self.imgs[idx] * 255
+        # Add extra dimension to turn shape into (H, W) -> (H, W, C)
+        sample = sample.reshape(sample.shape + (1,))
+
+        if self.transform:
+            sample = self.transform(sample)
+        # Since there are no labels, we just return 0 for the "label" here
+        return sample, 0
+
+class CelebADataset(Dataset):
+    """CelebA dataset with 64 by 64 images."""
+    def __init__(self, path_to_data, subsample=1, transform=None):
+        """
+        Parameters
+        ----------
+        subsample : int
+            Only load every |subsample| number of images.
+        """
+        self.img_paths = glob.glob(path_to_data + '/*')[::subsample]
+        self.transform = transform
+
+    def __len__(self):
+        return len(self.img_paths)
+
+    def __getitem__(self, idx):
+        sample_path = self.img_paths[idx]
+        sample = imread(sample_path)
+
+        if self.transform:
+            sample = self.transform(sample)
+        # Since there are no labels, we just return 0 for the "label" here
+        return sample, 0
+
+def get_imagelist_dataloader(batch_size=30, list_of_image_paths=None):
+    """dataloader with (64, 64) images."""
+    if not list_of_image_paths:
+        raise Exception('Must provide a list of image paths')
+    imagelist_data = ImageListDataset(list_of_image_paths,
+                                transform=transforms.ToTensor())
+    imagelist_loader = DataLoader(imagelist_data, batch_size=batch_size,
+                               shuffle=True)
+    return imagelist_loader
+
+class ImageListDataset(Dataset):
+    """Dress Sleeve Attribute Images - 216 x 261 x 3 for the most part."""
+    def __init__(self, list_of_image_paths, transform=None):
+        self.img_paths = list_of_image_paths
+        self.transform = transform
+
+    def __len__(self):
+        return len(self.img_paths)
+
+    def __getitem__(self, idx):
+        sample_path = self.img_paths[idx]
+        sample = imread(sample_path)
+
+        if self.transform:
+            sample = self.transform(sample)
+        # Since there are no labels, we just return 0 for the "label" here
+        return sample, 0
\ No newline at end of file
