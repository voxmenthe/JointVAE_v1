# first pass 128_v1 error message:
RuntimeError: size mismatch, m1: [1024 x 256], m2: [1024 x 256] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:249
--> 146         hidden = self.features_to_hidden(features.view(batch_size, -1))
# Second pass
RuntimeError: size mismatch, m1: [1024 x 256], m2: [2048 x 256]
# Third pass revert original change and use transpose:
Result: Starts training, but before end of epoch sizes change so fails


# Original with 1, 32, 32 or 3, 64, 64
VAE(
  (img_to_features): Sequential(
    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): ReLU()
    (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (7): ReLU()
  )
  (features_to_hidden): Sequential(
    (0): Linear(in_features=1024, out_features=256, bias=True)
    (1): ReLU()
  )
  (fc_mean): Linear(in_features=256, out_features=40, bias=True)
  (fc_log_var): Linear(in_features=256, out_features=40, bias=True)
  (fc_alphas): ModuleList(
    (0): Linear(in_features=256, out_features=40, bias=True)
  )
  (latent_to_features): Sequential(
    (0): Linear(in_features=80, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=1024, bias=True)
    (3): ReLU()
  )
  (features_to_img): Sequential(
    (0): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): ReLU()
    (2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (3): ReLU()
    (4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): ReLU()
    (6): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (7): Sigmoid()
  )
)