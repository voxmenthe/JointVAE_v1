{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from viz.visualize import Visualizer\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # change to your device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dress_dresslen_train_test_splits.json\tdress_sleeve_train_test_splits.json\r\n",
      "dress_sleevelen_train_test_splits.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./data/dress_dresslen_train_test_splits.json\", \"r\") as infile:\n",
    "    data_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train_1', 'y_train_1', 'X_test_1', 'y_test_1', 'X_train_2', 'y_train_2', 'X_test_2', 'y_test_2', 'X_train_3', 'y_train_3', 'X_test_3', 'y_test_3', 'X_train_4', 'y_train_4', 'X_test_4', 'y_test_4', 'X_train_5', 'y_train_5', 'X_test_5', 'y_test_5', 'X_train_6', 'y_train_6', 'X_test_6', 'y_test_6', 'X_train_7', 'y_train_7', 'X_test_7', 'y_test_7', 'X_train_8', 'y_train_8', 'X_test_8', 'y_test_8', 'X_train_9', 'y_train_9', 'X_test_9', 'y_test_9', 'X_train_10', 'y_train_10', 'X_test_10', 'y_test_10'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/2/8/2893552_3773662.jpg',\n",
       " '/2/9/2982376_3889235.jpg',\n",
       " '/2/7/2783355_3578973.jpg',\n",
       " '/2/9/2974380_3918638.jpg',\n",
       " '/2/8/2886740_3675612.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['X_train_1'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.5\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train image paths: 167,742\n",
      "Number of test image paths: 18,638\n",
      "\n",
      "Sample paths:\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/8/2893552_3773662.jpg\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/6/2683298_3676896.jpg\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/4/2431229_3158108.jpg\n",
      "/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables/2/5/2569101_3223742.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths_train = []\n",
    "image_paths_test = []\n",
    "\n",
    "root_data_dir = \"/home/jovyan/vmldata/raw_source_data/v20180810_all_wearables\"\n",
    "\n",
    "for key, val in data_dict.items():\n",
    "    if 'X_train' in key:\n",
    "        image_paths_train.extend([root_data_dir + imgpath for imgpath in val])\n",
    "    elif 'X_test' in key:\n",
    "        image_paths_test.extend([root_data_dir + imgpath for imgpath in val])\n",
    "\n",
    "print(f\"Number of train image paths: {len(image_paths_train):,d}\")\n",
    "print(f\"Number of test image paths: {len(image_paths_test):,d}\")\n",
    "print()\n",
    "print(\"Sample paths:\")\n",
    "print(image_paths_train[0])\n",
    "print(image_paths_train[-1])\n",
    "print(image_paths_test[0])\n",
    "print(image_paths_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.dataloaders import get_mnist_dataloaders, get_fashion_mnist_dataloaders\n",
    "#train_loader, test_loader = get_mnist_dataloaders(batch_size=64)\n",
    "#train_loader, test_loader = get_fashion_mnist_dataloaders(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from utils.dataloaders_custom import get_imagelist_dataloader, ImageListDataset\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "#composed = transforms.Compose([transforms.Resize((260,260)), transforms.ToTensor()])\n",
    "composed = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageListDataset(image_paths_train, transform=composed)\n",
    "test_dataset = ImageListDataset(image_paths_test, transform=composed)\n",
    "\n",
    "train_loader = get_imagelist_dataloader(batch_size=BATCH_SIZE, dataset_object=train_dataset)\n",
    "test_loader = get_imagelist_dataloader(batch_size=BATCH_SIZE, dataset_object=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "latent_spec = {'cont': 10,\n",
    "               'disc': [10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from jointvae.models_v1 import VAE\n",
    "from jointvae.models import VAE\n",
    "\n",
    "#model = VAE(latent_spec=latent_spec, img_size=(3, 260, 260), use_cuda=use_cuda)\n",
    "model = VAE(latent_spec=latent_spec, img_size=(3, 64, 64), use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (img_to_features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (features_to_hidden): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc_mean): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (fc_log_var): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (fc_alphas): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (features_to_img): Sequential(\n",
      "    (0): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, amsgrad=True) # added amsgrad # orig lr 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jointvae.training import Trainer\n",
    "\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "cont_capacity = [0.0, 5.0, 25000, 30.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 5.0, 25000, 30.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity,\n",
    "                 use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/167742\tLoss: 2831.572\n",
      "6400/167742\tLoss: 2417.275\n",
      "12800/167742\tLoss: 1492.403\n",
      "19200/167742\tLoss: 1394.205\n",
      "25600/167742\tLoss: 1362.082\n",
      "32000/167742\tLoss: 1347.232\n",
      "38400/167742\tLoss: 1333.981\n",
      "44800/167742\tLoss: 1333.034\n",
      "51200/167742\tLoss: 1323.519\n",
      "57600/167742\tLoss: 1320.870\n",
      "64000/167742\tLoss: 1305.000\n",
      "70400/167742\tLoss: 1305.948\n",
      "76800/167742\tLoss: 1290.296\n",
      "83200/167742\tLoss: 1293.515\n",
      "89600/167742\tLoss: 1277.715\n",
      "96000/167742\tLoss: 1274.329\n",
      "102400/167742\tLoss: 1266.086\n",
      "147200/167742\tLoss: 1235.774\n",
      "153600/167742\tLoss: 1232.759\n",
      "160000/167742\tLoss: 1237.104\n",
      "166400/167742\tLoss: 1227.729\n",
      "Epoch: 1 Average loss: 1337.91\n",
      "0/167742\tLoss: 1225.909\n",
      "6400/167742\tLoss: 1226.462\n",
      "12800/167742\tLoss: 1229.457\n",
      "19200/167742\tLoss: 1229.924\n",
      "25600/167742\tLoss: 1223.729\n",
      "32000/167742\tLoss: 1222.461\n",
      "38400/167742\tLoss: 1222.641\n",
      "44800/167742\tLoss: 1217.927\n",
      "51200/167742\tLoss: 1220.775\n",
      "57600/167742\tLoss: 1214.772\n",
      "64000/167742\tLoss: 1222.621\n",
      "70400/167742\tLoss: 1211.618\n",
      "76800/167742\tLoss: 1223.923\n",
      "83200/167742\tLoss: 1216.961\n",
      "89600/167742\tLoss: 1218.219\n",
      "96000/167742\tLoss: 1212.482\n",
      "102400/167742\tLoss: 1213.442\n",
      "108800/167742\tLoss: 1212.798\n",
      "115200/167742\tLoss: 1207.216\n",
      "121600/167742\tLoss: 1210.627\n",
      "128000/167742\tLoss: 1209.617\n",
      "134400/167742\tLoss: 1211.091\n",
      "140800/167742\tLoss: 1207.783\n",
      "147200/167742\tLoss: 1207.036\n",
      "153600/167742\tLoss: 1212.800\n",
      "160000/167742\tLoss: 1210.033\n",
      "166400/167742\tLoss: 1206.339\n",
      "Epoch: 2 Average loss: 1216.64\n",
      "0/167742\tLoss: 1221.461\n",
      "6400/167742\tLoss: 1203.216\n",
      "12800/167742\tLoss: 1204.082\n",
      "19200/167742\tLoss: 1204.575\n",
      "25600/167742\tLoss: 1200.536\n",
      "32000/167742\tLoss: 1196.797\n",
      "38400/167742\tLoss: 1198.669\n",
      "44800/167742\tLoss: 1200.444\n",
      "51200/167742\tLoss: 1196.251\n",
      "57600/167742\tLoss: 1195.344\n",
      "64000/167742\tLoss: 1200.369\n",
      "70400/167742\tLoss: 1196.680\n",
      "76800/167742\tLoss: 1201.945\n",
      "83200/167742\tLoss: 1193.308\n",
      "89600/167742\tLoss: 1194.018\n",
      "96000/167742\tLoss: 1197.303\n",
      "102400/167742\tLoss: 1190.972\n",
      "108800/167742\tLoss: 1194.980\n",
      "115200/167742\tLoss: 1198.409\n",
      "121600/167742\tLoss: 1192.717\n",
      "128000/167742\tLoss: 1199.302\n",
      "134400/167742\tLoss: 1190.029\n",
      "140800/167742\tLoss: 1189.025\n",
      "147200/167742\tLoss: 1188.271\n",
      "153600/167742\tLoss: 1187.579\n",
      "160000/167742\tLoss: 1188.775\n",
      "166400/167742\tLoss: 1183.159\n",
      "Epoch: 3 Average loss: 1196.03\n",
      "0/167742\tLoss: 1202.101\n",
      "6400/167742\tLoss: 1187.533\n",
      "12800/167742\tLoss: 1193.304\n",
      "19200/167742\tLoss: 1184.908\n",
      "25600/167742\tLoss: 1181.475\n",
      "32000/167742\tLoss: 1182.516\n",
      "38400/167742\tLoss: 1179.586\n",
      "44800/167742\tLoss: 1184.957\n",
      "51200/167742\tLoss: 1179.553\n",
      "57600/167742\tLoss: 1181.853\n",
      "64000/167742\tLoss: 1180.238\n",
      "70400/167742\tLoss: 1184.533\n",
      "76800/167742\tLoss: 1179.902\n",
      "83200/167742\tLoss: 1179.095\n",
      "89600/167742\tLoss: 1181.441\n",
      "96000/167742\tLoss: 1180.142\n",
      "102400/167742\tLoss: 1177.072\n",
      "108800/167742\tLoss: 1176.280\n",
      "115200/167742\tLoss: 1182.056\n",
      "121600/167742\tLoss: 1177.245\n",
      "128000/167742\tLoss: 1176.627\n",
      "134400/167742\tLoss: 1178.260\n",
      "140800/167742\tLoss: 1167.856\n",
      "147200/167742\tLoss: 1175.208\n",
      "153600/167742\tLoss: 1175.855\n",
      "160000/167742\tLoss: 1174.050\n",
      "166400/167742\tLoss: 1175.005\n",
      "Epoch: 4 Average loss: 1180.29\n",
      "0/167742\tLoss: 1176.870\n",
      "6400/167742\tLoss: 1172.881\n",
      "12800/167742\tLoss: 1171.460\n",
      "19200/167742\tLoss: 1172.535\n",
      "25600/167742\tLoss: 1172.273\n",
      "32000/167742\tLoss: 1173.125\n",
      "38400/167742\tLoss: 1170.606\n",
      "44800/167742\tLoss: 1169.768\n",
      "51200/167742\tLoss: 1171.009\n",
      "57600/167742\tLoss: 1173.788\n",
      "64000/167742\tLoss: 1169.853\n",
      "70400/167742\tLoss: 1169.557\n",
      "76800/167742\tLoss: 1168.319\n",
      "83200/167742\tLoss: 1165.135\n",
      "89600/167742\tLoss: 1165.422\n",
      "96000/167742\tLoss: 1169.178\n",
      "102400/167742\tLoss: 1167.538\n",
      "108800/167742\tLoss: 1165.416\n",
      "115200/167742\tLoss: 1171.368\n",
      "121600/167742\tLoss: 1161.252\n",
      "128000/167742\tLoss: 1164.998\n",
      "134400/167742\tLoss: 1167.798\n",
      "140800/167742\tLoss: 1158.248\n",
      "147200/167742\tLoss: 1165.522\n",
      "153600/167742\tLoss: 1155.886\n",
      "160000/167742\tLoss: 1158.754\n",
      "166400/167742\tLoss: 1159.894\n",
      "Epoch: 5 Average loss: 1167.77\n",
      "0/167742\tLoss: 1186.001\n",
      "6400/167742\tLoss: 1160.697\n",
      "12800/167742\tLoss: 1160.499\n",
      "19200/167742\tLoss: 1163.315\n",
      "25600/167742\tLoss: 1154.575\n",
      "32000/167742\tLoss: 1159.127\n",
      "38400/167742\tLoss: 1162.520\n",
      "44800/167742\tLoss: 1149.379\n",
      "51200/167742\tLoss: 1160.151\n",
      "57600/167742\tLoss: 1160.130\n",
      "64000/167742\tLoss: 1162.184\n",
      "70400/167742\tLoss: 1156.769\n",
      "76800/167742\tLoss: 1156.097\n",
      "83200/167742\tLoss: 1154.981\n",
      "89600/167742\tLoss: 1154.833\n",
      "96000/167742\tLoss: 1151.832\n",
      "102400/167742\tLoss: 1155.384\n",
      "108800/167742\tLoss: 1157.643\n",
      "115200/167742\tLoss: 1154.989\n",
      "121600/167742\tLoss: 1154.001\n",
      "128000/167742\tLoss: 1156.386\n",
      "134400/167742\tLoss: 1154.499\n",
      "140800/167742\tLoss: 1149.800\n",
      "147200/167742\tLoss: 1159.653\n",
      "153600/167742\tLoss: 1148.622\n",
      "160000/167742\tLoss: 1160.792\n",
      "166400/167742\tLoss: 1147.814\n",
      "Epoch: 6 Average loss: 1156.78\n",
      "0/167742\tLoss: 1137.253\n",
      "6400/167742\tLoss: 1150.861\n",
      "12800/167742\tLoss: 1149.287\n",
      "19200/167742\tLoss: 1149.729\n",
      "25600/167742\tLoss: 1151.290\n",
      "32000/167742\tLoss: 1149.149\n",
      "38400/167742\tLoss: 1148.077\n",
      "44800/167742\tLoss: 1150.356\n",
      "51200/167742\tLoss: 1150.255\n",
      "57600/167742\tLoss: 1146.512\n",
      "64000/167742\tLoss: 1153.143\n",
      "70400/167742\tLoss: 1153.150\n",
      "76800/167742\tLoss: 1147.459\n",
      "83200/167742\tLoss: 1141.701\n",
      "89600/167742\tLoss: 1147.310\n",
      "96000/167742\tLoss: 1145.742\n",
      "102400/167742\tLoss: 1148.921\n",
      "108800/167742\tLoss: 1150.019\n",
      "115200/167742\tLoss: 1144.209\n",
      "121600/167742\tLoss: 1151.940\n",
      "128000/167742\tLoss: 1147.411\n",
      "134400/167742\tLoss: 1142.507\n",
      "140800/167742\tLoss: 1142.100\n",
      "147200/167742\tLoss: 1145.261\n",
      "153600/167742\tLoss: 1144.803\n",
      "160000/167742\tLoss: 1143.838\n",
      "166400/167742\tLoss: 1143.486\n",
      "Epoch: 7 Average loss: 1148.15\n",
      "0/167742\tLoss: 1144.189\n",
      "6400/167742\tLoss: 1151.352\n",
      "12800/167742\tLoss: 1145.342\n",
      "19200/167742\tLoss: 1139.836\n",
      "25600/167742\tLoss: 1146.839\n",
      "32000/167742\tLoss: 1144.505\n",
      "38400/167742\tLoss: 1139.584\n",
      "44800/167742\tLoss: 1146.255\n",
      "51200/167742\tLoss: 1141.490\n",
      "57600/167742\tLoss: 1147.059\n",
      "64000/167742\tLoss: 1139.795\n",
      "70400/167742\tLoss: 1143.362\n",
      "76800/167742\tLoss: 1144.832\n",
      "83200/167742\tLoss: 1138.667\n",
      "89600/167742\tLoss: 1137.831\n",
      "96000/167742\tLoss: 1143.349\n",
      "102400/167742\tLoss: 1144.340\n",
      "108800/167742\tLoss: 1140.361\n",
      "115200/167742\tLoss: 1138.109\n",
      "121600/167742\tLoss: 1139.410\n",
      "128000/167742\tLoss: 1141.870\n",
      "134400/167742\tLoss: 1137.759\n",
      "140800/167742\tLoss: 1141.472\n",
      "147200/167742\tLoss: 1141.656\n",
      "153600/167742\tLoss: 1138.687\n",
      "160000/167742\tLoss: 1137.871\n",
      "166400/167742\tLoss: 1137.827\n",
      "Epoch: 8 Average loss: 1142.50\n",
      "0/167742\tLoss: 1083.027\n",
      "6400/167742\tLoss: 1140.380\n",
      "12800/167742\tLoss: 1143.049\n",
      "19200/167742\tLoss: 1141.972\n",
      "25600/167742\tLoss: 1138.413\n",
      "32000/167742\tLoss: 1139.420\n",
      "38400/167742\tLoss: 1141.582\n",
      "44800/167742\tLoss: 1141.503\n",
      "51200/167742\tLoss: 1136.148\n",
      "57600/167742\tLoss: 1141.926\n",
      "64000/167742\tLoss: 1140.663\n",
      "70400/167742\tLoss: 1141.112\n",
      "76800/167742\tLoss: 1135.551\n",
      "83200/167742\tLoss: 1142.715\n",
      "89600/167742\tLoss: 1139.796\n",
      "96000/167742\tLoss: 1140.221\n",
      "102400/167742\tLoss: 1139.744\n",
      "108800/167742\tLoss: 1140.909\n",
      "115200/167742\tLoss: 1137.057\n",
      "121600/167742\tLoss: 1138.884\n",
      "128000/167742\tLoss: 1137.976\n",
      "134400/167742\tLoss: 1142.902\n",
      "140800/167742\tLoss: 1140.984\n",
      "147200/167742\tLoss: 1139.127\n",
      "153600/167742\tLoss: 1140.146\n",
      "160000/167742\tLoss: 1136.745\n",
      "166400/167742\tLoss: 1139.617\n",
      "Epoch: 9 Average loss: 1140.32\n",
      "0/167742\tLoss: 1137.308\n",
      "6400/167742\tLoss: 1138.181\n",
      "12800/167742\tLoss: 1138.008\n",
      "19200/167742\tLoss: 1135.861\n",
      "25600/167742\tLoss: 1139.742\n",
      "32000/167742\tLoss: 1134.825\n",
      "38400/167742\tLoss: 1137.088\n",
      "44800/167742\tLoss: 1136.581\n",
      "51200/167742\tLoss: 1141.965\n",
      "57600/167742\tLoss: 1137.916\n",
      "64000/167742\tLoss: 1139.444\n",
      "70400/167742\tLoss: 1146.908\n",
      "76800/167742\tLoss: 1137.034\n",
      "83200/167742\tLoss: 1135.108\n",
      "89600/167742\tLoss: 1143.843\n",
      "96000/167742\tLoss: 1133.315\n",
      "102400/167742\tLoss: 1138.991\n",
      "108800/167742\tLoss: 1138.390\n",
      "115200/167742\tLoss: 1136.182\n",
      "121600/167742\tLoss: 1136.197\n",
      "128000/167742\tLoss: 1140.841\n",
      "134400/167742\tLoss: 1130.693\n",
      "140800/167742\tLoss: 1135.919\n",
      "147200/167742\tLoss: 1131.377\n",
      "153600/167742\tLoss: 1138.490\n",
      "160000/167742\tLoss: 1134.751\n",
      "166400/167742\tLoss: 1135.204\n",
      "Epoch: 10 Average loss: 1137.79\n",
      "0/167742\tLoss: 1156.064\n",
      "6400/167742\tLoss: 1135.415\n",
      "12800/167742\tLoss: 1137.333\n",
      "19200/167742\tLoss: 1136.163\n",
      "25600/167742\tLoss: 1136.858\n",
      "32000/167742\tLoss: 1131.182\n",
      "38400/167742\tLoss: 1135.272\n",
      "44800/167742\tLoss: 1140.010\n",
      "51200/167742\tLoss: 1132.307\n",
      "57600/167742\tLoss: 1132.862\n",
      "64000/167742\tLoss: 1125.735\n",
      "70400/167742\tLoss: 1130.343\n",
      "76800/167742\tLoss: 1134.908\n",
      "83200/167742\tLoss: 1132.723\n",
      "89600/167742\tLoss: 1136.500\n",
      "96000/167742\tLoss: 1136.331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102400/167742\tLoss: 1135.066\n",
      "108800/167742\tLoss: 1128.470\n",
      "115200/167742\tLoss: 1129.962\n",
      "121600/167742\tLoss: 1131.605\n",
      "128000/167742\tLoss: 1127.597\n",
      "134400/167742\tLoss: 1129.201\n",
      "140800/167742\tLoss: 1131.965\n",
      "147200/167742\tLoss: 1134.628\n",
      "153600/167742\tLoss: 1136.473\n",
      "160000/167742\tLoss: 1130.931\n",
      "166400/167742\tLoss: 1129.364\n",
      "Epoch: 11 Average loss: 1133.53\n",
      "0/167742\tLoss: 1114.932\n",
      "6400/167742\tLoss: 1130.742\n",
      "12800/167742\tLoss: 1125.854\n",
      "19200/167742\tLoss: 1127.512\n",
      "25600/167742\tLoss: 1133.775\n",
      "32000/167742\tLoss: 1130.888\n",
      "38400/167742\tLoss: 1134.755\n",
      "44800/167742\tLoss: 1125.815\n",
      "51200/167742\tLoss: 1131.315\n",
      "57600/167742\tLoss: 1131.392\n",
      "64000/167742\tLoss: 1136.174\n",
      "70400/167742\tLoss: 1129.225\n",
      "76800/167742\tLoss: 1128.345\n",
      "83200/167742\tLoss: 1129.105\n",
      "89600/167742\tLoss: 1133.391\n",
      "96000/167742\tLoss: 1131.670\n",
      "102400/167742\tLoss: 1131.869\n",
      "108800/167742\tLoss: 1131.745\n",
      "115200/167742\tLoss: 1127.347\n",
      "121600/167742\tLoss: 1131.051\n",
      "128000/167742\tLoss: 1129.097\n",
      "134400/167742\tLoss: 1127.836\n",
      "140800/167742\tLoss: 1129.432\n",
      "147200/167742\tLoss: 1126.046\n",
      "153600/167742\tLoss: 1128.964\n",
      "160000/167742\tLoss: 1121.461\n",
      "166400/167742\tLoss: 1128.417\n",
      "Epoch: 12 Average loss: 1130.18\n",
      "0/167742\tLoss: 1127.456\n",
      "6400/167742\tLoss: 1128.893\n",
      "12800/167742\tLoss: 1130.274\n",
      "19200/167742\tLoss: 1126.568\n",
      "25600/167742\tLoss: 1129.964\n",
      "32000/167742\tLoss: 1127.116\n",
      "38400/167742\tLoss: 1132.499\n",
      "44800/167742\tLoss: 1125.710\n",
      "51200/167742\tLoss: 1127.626\n",
      "57600/167742\tLoss: 1131.765\n",
      "64000/167742\tLoss: 1125.626\n",
      "70400/167742\tLoss: 1122.831\n",
      "76800/167742\tLoss: 1126.200\n",
      "83200/167742\tLoss: 1125.941\n",
      "89600/167742\tLoss: 1124.548\n",
      "96000/167742\tLoss: 1131.900\n",
      "102400/167742\tLoss: 1123.384\n",
      "108800/167742\tLoss: 1126.223\n",
      "115200/167742\tLoss: 1127.647\n",
      "121600/167742\tLoss: 1125.792\n",
      "128000/167742\tLoss: 1126.258\n",
      "134400/167742\tLoss: 1127.663\n",
      "140800/167742\tLoss: 1122.229\n",
      "147200/167742\tLoss: 1130.706\n",
      "153600/167742\tLoss: 1121.996\n",
      "160000/167742\tLoss: 1123.960\n",
      "166400/167742\tLoss: 1121.546\n",
      "Epoch: 13 Average loss: 1127.20\n",
      "0/167742\tLoss: 1129.662\n",
      "6400/167742\tLoss: 1128.039\n",
      "12800/167742\tLoss: 1126.515\n",
      "19200/167742\tLoss: 1123.661\n",
      "25600/167742\tLoss: 1123.280\n",
      "32000/167742\tLoss: 1124.645\n",
      "38400/167742\tLoss: 1119.053\n",
      "44800/167742\tLoss: 1125.406\n",
      "51200/167742\tLoss: 1121.803\n",
      "57600/167742\tLoss: 1127.148\n",
      "64000/167742\tLoss: 1120.185\n",
      "70400/167742\tLoss: 1126.805\n",
      "76800/167742\tLoss: 1124.095\n",
      "83200/167742\tLoss: 1116.138\n",
      "89600/167742\tLoss: 1129.336\n",
      "96000/167742\tLoss: 1124.866\n",
      "102400/167742\tLoss: 1122.031\n",
      "108800/167742\tLoss: 1125.680\n",
      "115200/167742\tLoss: 1120.824\n",
      "121600/167742\tLoss: 1120.693\n",
      "128000/167742\tLoss: 1129.197\n",
      "134400/167742\tLoss: 1119.616\n",
      "140800/167742\tLoss: 1123.170\n",
      "147200/167742\tLoss: 1118.822\n",
      "153600/167742\tLoss: 1121.855\n",
      "160000/167742\tLoss: 1122.721\n",
      "166400/167742\tLoss: 1121.173\n",
      "Epoch: 14 Average loss: 1123.84\n",
      "0/167742\tLoss: 1119.365\n",
      "6400/167742\tLoss: 1117.953\n",
      "12800/167742\tLoss: 1122.865\n",
      "19200/167742\tLoss: 1125.406\n",
      "25600/167742\tLoss: 1119.275\n",
      "32000/167742\tLoss: 1127.065\n",
      "38400/167742\tLoss: 1120.667\n",
      "44800/167742\tLoss: 1116.633\n",
      "51200/167742\tLoss: 1122.291\n",
      "57600/167742\tLoss: 1113.651\n",
      "64000/167742\tLoss: 1118.329\n",
      "70400/167742\tLoss: 1118.816\n",
      "76800/167742\tLoss: 1119.833\n",
      "83200/167742\tLoss: 1125.905\n",
      "89600/167742\tLoss: 1125.430\n",
      "96000/167742\tLoss: 1122.246\n",
      "102400/167742\tLoss: 1125.557\n",
      "108800/167742\tLoss: 1119.165\n",
      "115200/167742\tLoss: 1117.618\n",
      "121600/167742\tLoss: 1122.555\n",
      "128000/167742\tLoss: 1123.032\n",
      "134400/167742\tLoss: 1124.925\n",
      "140800/167742\tLoss: 1120.660\n",
      "147200/167742\tLoss: 1119.886\n",
      "153600/167742\tLoss: 1115.941\n",
      "160000/167742\tLoss: 1114.768\n",
      "166400/167742\tLoss: 1120.176\n",
      "Epoch: 15 Average loss: 1121.32\n",
      "0/167742\tLoss: 1125.209\n",
      "6400/167742\tLoss: 1121.737\n",
      "12800/167742\tLoss: 1115.269\n",
      "19200/167742\tLoss: 1116.227\n",
      "25600/167742\tLoss: 1126.207\n",
      "32000/167742\tLoss: 1118.629\n",
      "38400/167742\tLoss: 1116.060\n",
      "44800/167742\tLoss: 1114.582\n",
      "51200/167742\tLoss: 1120.616\n",
      "57600/167742\tLoss: 1116.897\n",
      "64000/167742\tLoss: 1118.335\n",
      "70400/167742\tLoss: 1120.862\n",
      "76800/167742\tLoss: 1118.283\n",
      "83200/167742\tLoss: 1116.131\n",
      "89600/167742\tLoss: 1117.993\n",
      "96000/167742\tLoss: 1118.643\n",
      "102400/167742\tLoss: 1122.246\n",
      "108800/167742\tLoss: 1114.468\n",
      "115200/167742\tLoss: 1116.348\n",
      "121600/167742\tLoss: 1119.614\n",
      "128000/167742\tLoss: 1119.884\n",
      "134400/167742\tLoss: 1118.648\n",
      "140800/167742\tLoss: 1119.689\n",
      "147200/167742\tLoss: 1118.243\n",
      "153600/167742\tLoss: 1118.061\n",
      "160000/167742\tLoss: 1117.769\n",
      "166400/167742\tLoss: 1115.192\n",
      "Epoch: 16 Average loss: 1118.79\n",
      "0/167742\tLoss: 1094.357\n",
      "6400/167742\tLoss: 1117.154\n",
      "12800/167742\tLoss: 1133.058\n",
      "19200/167742\tLoss: 1120.529\n",
      "25600/167742\tLoss: 1120.545\n",
      "32000/167742\tLoss: 1121.467\n",
      "38400/167742\tLoss: 1114.017\n",
      "44800/167742\tLoss: 1113.301\n",
      "51200/167742\tLoss: 1116.138\n",
      "57600/167742\tLoss: 1115.007\n",
      "64000/167742\tLoss: 1116.840\n",
      "70400/167742\tLoss: 1113.427\n",
      "76800/167742\tLoss: 1110.990\n",
      "83200/167742\tLoss: 1119.615\n",
      "89600/167742\tLoss: 1115.055\n",
      "96000/167742\tLoss: 1115.454\n",
      "102400/167742\tLoss: 1116.209\n",
      "108800/167742\tLoss: 1113.957\n",
      "115200/167742\tLoss: 1116.807\n",
      "121600/167742\tLoss: 1118.007\n",
      "128000/167742\tLoss: 1113.570\n",
      "134400/167742\tLoss: 1111.856\n",
      "140800/167742\tLoss: 1110.598\n",
      "147200/167742\tLoss: 1117.671\n",
      "153600/167742\tLoss: 1114.460\n",
      "160000/167742\tLoss: 1112.682\n",
      "166400/167742\tLoss: 1116.091\n",
      "Epoch: 17 Average loss: 1116.68\n",
      "0/167742\tLoss: 1103.730\n",
      "6400/167742\tLoss: 1110.564\n",
      "12800/167742\tLoss: 1111.120\n",
      "19200/167742\tLoss: 1113.754\n",
      "25600/167742\tLoss: 1120.754\n",
      "32000/167742\tLoss: 1119.405\n",
      "38400/167742\tLoss: 1109.683\n",
      "44800/167742\tLoss: 1119.069\n",
      "51200/167742\tLoss: 1118.560\n",
      "57600/167742\tLoss: 1113.900\n",
      "64000/167742\tLoss: 1110.939\n",
      "70400/167742\tLoss: 1110.396\n",
      "76800/167742\tLoss: 1115.338\n",
      "83200/167742\tLoss: 1115.564\n",
      "89600/167742\tLoss: 1116.027\n",
      "96000/167742\tLoss: 1118.048\n",
      "102400/167742\tLoss: 1104.743\n",
      "108800/167742\tLoss: 1108.984\n",
      "115200/167742\tLoss: 1113.633\n",
      "121600/167742\tLoss: 1116.082\n",
      "128000/167742\tLoss: 1114.836\n",
      "134400/167742\tLoss: 1115.600\n",
      "140800/167742\tLoss: 1108.146\n",
      "147200/167742\tLoss: 1106.460\n",
      "153600/167742\tLoss: 1110.569\n",
      "160000/167742\tLoss: 1108.234\n",
      "166400/167742\tLoss: 1114.697\n",
      "Epoch: 18 Average loss: 1113.60\n",
      "0/167742\tLoss: 1108.595\n",
      "6400/167742\tLoss: 1109.331\n",
      "12800/167742\tLoss: 1110.182\n",
      "19200/167742\tLoss: 1113.381\n",
      "25600/167742\tLoss: 1112.212\n",
      "32000/167742\tLoss: 1114.873\n",
      "38400/167742\tLoss: 1107.961\n",
      "44800/167742\tLoss: 1117.302\n",
      "51200/167742\tLoss: 1110.324\n",
      "57600/167742\tLoss: 1114.065\n",
      "64000/167742\tLoss: 1105.374\n",
      "70400/167742\tLoss: 1110.402\n",
      "76800/167742\tLoss: 1115.144\n",
      "83200/167742\tLoss: 1109.196\n",
      "89600/167742\tLoss: 1113.010\n",
      "96000/167742\tLoss: 1112.954\n",
      "102400/167742\tLoss: 1103.539\n",
      "108800/167742\tLoss: 1113.276\n",
      "115200/167742\tLoss: 1114.359\n",
      "121600/167742\tLoss: 1107.541\n",
      "128000/167742\tLoss: 1105.189\n",
      "134400/167742\tLoss: 1108.667\n",
      "140800/167742\tLoss: 1113.294\n",
      "147200/167742\tLoss: 1108.491\n",
      "153600/167742\tLoss: 1107.359\n",
      "160000/167742\tLoss: 1112.253\n",
      "166400/167742\tLoss: 1116.123\n",
      "Epoch: 19 Average loss: 1111.49\n",
      "0/167742\tLoss: 1096.771\n",
      "6400/167742\tLoss: 1111.189\n",
      "12800/167742\tLoss: 1112.207\n",
      "19200/167742\tLoss: 1112.252\n",
      "25600/167742\tLoss: 1106.887\n",
      "32000/167742\tLoss: 1114.896\n",
      "38400/167742\tLoss: 1114.064\n",
      "44800/167742\tLoss: 1107.278\n",
      "51200/167742\tLoss: 1106.960\n",
      "57600/167742\tLoss: 1106.065\n",
      "64000/167742\tLoss: 1106.726\n",
      "70400/167742\tLoss: 1106.412\n",
      "76800/167742\tLoss: 1113.413\n",
      "83200/167742\tLoss: 1109.351\n",
      "89600/167742\tLoss: 1109.684\n",
      "96000/167742\tLoss: 1118.827\n",
      "102400/167742\tLoss: 1109.317\n",
      "108800/167742\tLoss: 1103.866\n",
      "115200/167742\tLoss: 1113.730\n",
      "121600/167742\tLoss: 1109.260\n",
      "128000/167742\tLoss: 1102.697\n",
      "134400/167742\tLoss: 1109.703\n",
      "140800/167742\tLoss: 1103.084\n",
      "147200/167742\tLoss: 1106.988\n",
      "153600/167742\tLoss: 1109.340\n",
      "160000/167742\tLoss: 1108.076\n",
      "166400/167742\tLoss: 1105.731\n",
      "Epoch: 20 Average loss: 1109.57\n",
      "0/167742\tLoss: 1070.252\n",
      "6400/167742\tLoss: 1109.009\n",
      "12800/167742\tLoss: 1108.722\n",
      "19200/167742\tLoss: 1106.186\n",
      "25600/167742\tLoss: 1103.674\n",
      "32000/167742\tLoss: 1118.586\n",
      "38400/167742\tLoss: 1110.876\n",
      "44800/167742\tLoss: 1110.094\n",
      "51200/167742\tLoss: 1108.077\n",
      "57600/167742\tLoss: 1106.365\n",
      "64000/167742\tLoss: 1108.919\n",
      "70400/167742\tLoss: 1109.557\n",
      "76800/167742\tLoss: 1104.898\n",
      "83200/167742\tLoss: 1107.134\n",
      "89600/167742\tLoss: 1108.603\n",
      "96000/167742\tLoss: 1104.327\n",
      "102400/167742\tLoss: 1105.776\n",
      "108800/167742\tLoss: 1116.097\n",
      "115200/167742\tLoss: 1107.919\n",
      "121600/167742\tLoss: 1104.844\n",
      "128000/167742\tLoss: 1105.224\n",
      "134400/167742\tLoss: 1112.563\n",
      "140800/167742\tLoss: 1110.791\n",
      "147200/167742\tLoss: 1106.517\n",
      "153600/167742\tLoss: 1102.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000/167742\tLoss: 1108.593\n",
      "166400/167742\tLoss: 1107.768\n",
      "Epoch: 21 Average loss: 1108.64\n",
      "0/167742\tLoss: 1107.178\n",
      "6400/167742\tLoss: 1112.482\n",
      "12800/167742\tLoss: 1104.009\n",
      "19200/167742\tLoss: 1113.057\n",
      "25600/167742\tLoss: 1111.112\n",
      "32000/167742\tLoss: 1106.684\n",
      "38400/167742\tLoss: 1105.450\n",
      "44800/167742\tLoss: 1105.249\n",
      "51200/167742\tLoss: 1105.511\n",
      "57600/167742\tLoss: 1103.406\n",
      "64000/167742\tLoss: 1111.606\n",
      "70400/167742\tLoss: 1107.103\n",
      "76800/167742\tLoss: 1098.819\n",
      "83200/167742\tLoss: 1107.153\n",
      "89600/167742\tLoss: 1111.015\n",
      "96000/167742\tLoss: 1101.297\n",
      "102400/167742\tLoss: 1107.291\n",
      "108800/167742\tLoss: 1110.989\n",
      "115200/167742\tLoss: 1111.016\n",
      "121600/167742\tLoss: 1101.204\n",
      "128000/167742\tLoss: 1116.688\n",
      "134400/167742\tLoss: 1107.441\n",
      "140800/167742\tLoss: 1104.724\n",
      "147200/167742\tLoss: 1111.733\n",
      "153600/167742\tLoss: 1109.464\n",
      "160000/167742\tLoss: 1108.320\n",
      "166400/167742\tLoss: 1110.740\n",
      "Epoch: 22 Average loss: 1108.26\n",
      "0/167742\tLoss: 1114.038\n",
      "6400/167742\tLoss: 1110.504\n",
      "12800/167742\tLoss: 1103.178\n",
      "19200/167742\tLoss: 1105.872\n",
      "25600/167742\tLoss: 1101.207\n",
      "32000/167742\tLoss: 1107.123\n",
      "38400/167742\tLoss: 1106.824\n",
      "44800/167742\tLoss: 1106.075\n",
      "51200/167742\tLoss: 1105.244\n",
      "57600/167742\tLoss: 1111.750\n",
      "64000/167742\tLoss: 1105.229\n",
      "70400/167742\tLoss: 1103.871\n",
      "76800/167742\tLoss: 1110.469\n",
      "83200/167742\tLoss: 1109.613\n",
      "89600/167742\tLoss: 1112.895\n",
      "96000/167742\tLoss: 1103.100\n",
      "102400/167742\tLoss: 1107.556\n",
      "108800/167742\tLoss: 1108.682\n",
      "115200/167742\tLoss: 1110.570\n",
      "121600/167742\tLoss: 1107.990\n",
      "128000/167742\tLoss: 1104.534\n",
      "134400/167742\tLoss: 1112.638\n",
      "140800/167742\tLoss: 1108.392\n",
      "147200/167742\tLoss: 1107.903\n",
      "153600/167742\tLoss: 1107.732\n",
      "160000/167742\tLoss: 1106.188\n",
      "166400/167742\tLoss: 1105.424\n",
      "Epoch: 23 Average loss: 1107.73\n",
      "0/167742\tLoss: 1090.270\n",
      "6400/167742\tLoss: 1111.989\n",
      "12800/167742\tLoss: 1106.342\n",
      "19200/167742\tLoss: 1106.482\n",
      "25600/167742\tLoss: 1107.647\n",
      "32000/167742\tLoss: 1107.486\n",
      "38400/167742\tLoss: 1103.959\n",
      "44800/167742\tLoss: 1107.359\n",
      "51200/167742\tLoss: 1106.800\n",
      "57600/167742\tLoss: 1112.456\n",
      "64000/167742\tLoss: 1107.824\n",
      "70400/167742\tLoss: 1103.296\n",
      "76800/167742\tLoss: 1102.299\n",
      "83200/167742\tLoss: 1107.747\n",
      "89600/167742\tLoss: 1107.023\n",
      "96000/167742\tLoss: 1112.547\n",
      "102400/167742\tLoss: 1103.110\n",
      "108800/167742\tLoss: 1103.977\n",
      "115200/167742\tLoss: 1101.103\n",
      "121600/167742\tLoss: 1101.042\n",
      "128000/167742\tLoss: 1109.956\n",
      "134400/167742\tLoss: 1108.025\n",
      "140800/167742\tLoss: 1103.750\n",
      "147200/167742\tLoss: 1098.675\n",
      "153600/167742\tLoss: 1101.342\n",
      "160000/167742\tLoss: 1108.597\n",
      "166400/167742\tLoss: 1100.865\n",
      "Epoch: 24 Average loss: 1106.18\n",
      "0/167742\tLoss: 1118.077\n",
      "6400/167742\tLoss: 1098.737\n",
      "12800/167742\tLoss: 1106.784\n",
      "19200/167742\tLoss: 1111.838\n",
      "25600/167742\tLoss: 1108.229\n",
      "32000/167742\tLoss: 1107.533\n",
      "38400/167742\tLoss: 1104.386\n",
      "44800/167742\tLoss: 1105.603\n",
      "51200/167742\tLoss: 1106.154\n",
      "57600/167742\tLoss: 1109.143\n",
      "64000/167742\tLoss: 1102.663\n",
      "70400/167742\tLoss: 1105.087\n",
      "76800/167742\tLoss: 1109.717\n",
      "83200/167742\tLoss: 1104.912\n",
      "89600/167742\tLoss: 1102.430\n",
      "96000/167742\tLoss: 1105.022\n",
      "102400/167742\tLoss: 1100.934\n",
      "108800/167742\tLoss: 1101.097\n",
      "115200/167742\tLoss: 1104.251\n",
      "121600/167742\tLoss: 1098.632\n",
      "128000/167742\tLoss: 1101.416\n",
      "134400/167742\tLoss: 1108.420\n",
      "140800/167742\tLoss: 1102.581\n"
     ]
    }
   ],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "\n",
    "trainer.train(train_loader, epochs=200, save_training_gif=('./training_rd64x64_e200_b128.gif', viz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Get a batch of data\n",
    "for batch, labels in test_loader:\n",
    "    break\n",
    "\n",
    "# Reconstruct data using Joint-VAE model\n",
    "recon = viz.reconstructions(batch)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "#np.transpose(recon.numpy(), (2,1,0))\n",
    "plt.imshow(np.rot90(np.transpose(recon.numpy(),(2,1,0)),k=3));\n",
    "plt.savefig(\"sample_images/306/64/e200_b128_reconstructions.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "samples = viz.samples()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "#plt.imshow(samples.numpy()[0, :, :],cmap='gray');\n",
    "plt.imshow(np.rot90(np.transpose(samples.numpy(),(2,1,0)),k=3));\n",
    "plt.savefig(\"sample_images/306/64/e10_b20_samples.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all traversals\n",
    "traversals = viz.all_latent_traversals(size=10)\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(np.rot90(np.transpose(traversals.numpy(),(2,1,0)),k=3));\n",
    "plt.savefig(\"sample_images/306/64/e10_b20_all_traversals.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=2, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(np.rot90(np.transpose(traversals.numpy(),(2,1,0)),k=3));\n",
    "plt.savefig(\"sample_images/306/64/e10_b20_traversals2100.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=1, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(traversals.numpy()[0, :, :]);\n",
    "plt.imshow(np.rot90(np.transpose(traversals.numpy(),(2,1,0)),k=3));\n",
    "plt.savefig(\"sample_images/306/64/e10_b20_traversals1100.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=9, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "#plt.imshow(traversals.numpy()[0, :, :], cmap='gray');\n",
    "plt.imshow(np.rot90(np.transpose(traversals.numpy(),(2,1,0)),k=3));\n",
    "plt.savefig(\"sample_images/306/64/e10_b20_traversals9100.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"realdata64x64_e200_b128.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"statedict_\" + model_name) # save state dict\n",
    "torch.save(model, model_name) # save full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done training: \",model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore Model from State Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd_model = VAE(latent_spec=latent_spec, img_size=(3, 64, 64))\n",
    "sd_model.load_state_dict(torch.load(\"statedict_\" + model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore Full Model\n",
    "* Note in this case the serialized data is bound to the specific classes and exact directory strucutre used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = torch.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\trequirements.txt\r\n",
      "dataloading_pytorch_test.ipynb\tstatedict_jvae_fmnist_oct292018.pth\r\n",
      "imgs\t\t\t\ttrained_models\r\n",
      "jointvae\t\t\ttraining.gif\r\n",
      "jvae_fmnist_oct292018.pth\ttraining_rd1.gif\r\n",
      "latent_traversals.py\t\ttrain_model.ipynb\r\n",
      "load_model.ipynb\t\ttrain_model_realdata_306_260_v1.ipynb\r\n",
      "main.py\t\t\t\ttrain_model_realdata_64_v1.ipynb\r\n",
      "__pycache__\t\t\tutils\r\n",
      "RandomUtilsandTests.ipynb\tviz\r\n",
      "README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
